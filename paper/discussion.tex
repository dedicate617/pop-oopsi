The main result of this work is that given only noisy, temporally subsampled, calcium imaging observations from a population of neurons, we can efficiently infer the most likely functional connection matrix.  More specifically, we show that for reasonable assumptions about the parameters of the neurons (c.f Figure \ref{fig:recvar-SNR}), and about $10$ minutes of simulated data (c.f. Figure \ref{fig:recvar-NT}), we can accurately reconstruct the connection matrix, in only about $10$ of computational time, when running our algorithm on a high-perform cluster.  And while our estimates exhibit some scale error (c.f. Figure \ref{fig:scatters}), the scale error is explained by the poor temporal resolution inherent in the data (c.f. Figure \ref{fig:bias}).  These results depend on a few theoretical advancements.  First, we develop an embedded-chain-within-blockwise-Gibbs algorithm for jointly sampling spike trains, given the calcium traces. Then, we show that by factorizing, we can obtain approximately equally good estimates (c.f. Figure \ref{fig:scatters}), which greatly expedites the computations.  Finally, we can impose a sparse prior on the connection matrix, justified by recent experimental findings \cite{Chlovksii}, to reduce the amount of observations necessary to obtain good estimates (c.f. Figure \ref{fig:sparse} and \ref{fig:distros}).  And while our approach breaks down in the face of strong correlations (c.f. Figure \ref{fig:rasters}), the algorithm fairs well under certain model misspecifications (c.f. Figure \ref{fig:vartau}).  

Importantly, the above-described approach for learning a functional connection matrix differs significantly from previous work.  Naively, one can define functional connectivity between a pair of neurons as some function of their two spike trains, $f(\bn_1,\bn_2)$.  Examples of such functions include correlation coefficient, lagged cross-correlation, transfer entropy, and Granger causality.  These measures are problematic, in that they implicitly ignore the spike trains of all other neurons.  One would rather have a measure of connectivity that is conditioned on the spike trains of all observable neurons, i.e., $f(\bn_1,\bn_2 | \bn_3, \ldots, \bn_N)$.  Several groups have recently developed methods to infer pairwise connectivity conditioned on all other observable spike trains \cite{emory, liam, Garofalo, Vakorina, etc.}.  To our knowledge, however, this work represents the first attempt to infer connectivity given some data other than spike trains.  As the spikes contain all the information about connectivity, we therefore must infer the spike trains first, and then estimate the functional connectivity.  

While this strategy captures the pairwise dependency between neurons, conditioned on all the other observable spike trains, it is often the case that many unobservable neurons are impacting the spike train statistics.  Developing methods to cope with these unobserved neurons is currently an area of active investigation \cite{Duane 1 and 2, liam}.  Incorporating these features into our model to further improve our estimates is an important direction for future work.

Along with coping with unobserved neurons, we have considered several other potential directions.  First, incorporating photo-stimulation to activate or deactivate small subpopulations of neurons to reduce the uncertainty of our estimates could potentially significantly reduce the amount of experimental time required to obtain a particular $r^2$ value.  Second, a fully Bayesian algorithm, estimating distributions of all the parameters (necessitating establishing priors on each), as opposed to only finding the maximum a posteriori (MAP) estimate, would be desirable.  Third, certain adaptations of this approach might be necessary to apply these algorithms to real data, including dealing with multiple spikes per frame, non-stationarities (e.g., bleaching), etc.  All these advances are currently being pursued.




% \paragraph{j's outline of discussion}
% 
% \begin{itemize}
% \item summary of main point: using sparse prior, we can recover a large fraction of variance of connection weights, assuming reasonable SNR, parameters, and imaging rate.
% \item $h_j$ vs. $h_{ij}$ reduces dimensionality of hidden space to $O(N)$ vs. $O(N^2)$, leading to our approach scaling well as $N \rightarrow$ big
% \item $P(A|BC)\neq P(A|B)P(A|C)$ unless $B$ and $C$ are uncorrelated.  we use this property, correlation coefficient doesn't, cross-correlations, etc., do not.
% \item for the same reason, hidden neurons might be a problem for us.  faster imaging, etc., should help alleviate that.
% \item we can measure uncertainty in estimates, and use photo-stimulation to activate/deactivate small groups of neurons efficiently to help reduce variance in uncertainty.
% \item certainly the issue of common input and unobserved neurons should be addressed a bit more in the discussion.  
% \item we can also talk a bit more about future directions involving fully-bayesian inference of the parameters (ie, MCMC over the parameter space, not just over the hidden variables X) instead of the MAP approach we took here; i tried to set this up a bit in the methods.  
% \item other important future work to mention: real data, faster mcmc sampling methods, dealing with nonstationarities (e.g. bleaching).
% \item comparison with other work (e.g., duane's, Garofalo, Vakorina, transfer entropy, granger causality, etc.)
% \end{itemize}

% \paragraph{scale bias discussion}
% 
% Scale bias in principle may be removed by performing inference of the spike trains with the bin size $\Delta \rightarrow 0$. However, we were not successful in performing this calculation. One problem that we encountered with this approach was the increase in the variance of the connectivity estimates. In Eq.(\ref{eqn:likelihoodGLMmodb}) the coincident time bin $t=t'$ was omitted from the sum and so all spike pairs within the same time-bins were removed from the GLM fit. Because time position of such spike pairs inferred from fluorescence data typically would have inaccuracy $\approx \Delta$, temporal order of such spike pairs could often be confused, introducing ambiguity as to whether observed event should contribute to $w_{ij}$ or $w_{ji}$.
% 
% Really, if the number of spikes of one neuron following that of another neuron within $\Delta$ was $n(2\rightarrow 1)$, while such in the reverse order was $n(1\rightarrow 2)$, difference $\delta n_{12} = n(2\rightarrow 1)-n(1\rightarrow 2)$ would correspond to the difference of functional connectivity weights $\delta w_{12}=w_{12}-w_{21}$. However, when such spike pairs had had their order confused with large probability $p\approx 1/2$, the number of spike pairs $n(2\rightarrow 1)$ actually observed would become $(1-p) n(2\rightarrow 1)+p n(1\rightarrow 2)$, and similarly for the reverse. Empirically observed difference $w_{12}-w_{21}$ thus would correspondingly drop to $\delta w'_{12}= (1-2p)\delta w_{12}$, while the variance would remain the same. This effect complicated estimating of the functional connectivity matrix $W$ by effectively mixing $\w_{12}$ and $\w_{21}$ and introducing large error in $W$ estimates, moving them toward $(W+W^T)/2$.
% We observed that the amount of data necessary to overcome this noise due to disordering of closely positioned spike-pairs appeared to be well over $\approx 10$ min of data used for the most of the calculations shown in this section below. Such high-time-resolution samples of spike trains also were substantially more computationally expensive to obtain and work with. For these reasons, we did not pursue this line of research further, although it may be of interest in the future.


% \paragraph{y's mini-discussion}
% 
% Functional connectivity may fail to faithfully represent anatomical circuit structure if false correlations are present between different neurons, induced e.g. by common inputs, or if the dynamics of neural population is entirely concentrated on a low-dimensional subspace of the full configurational space ${\bf n}$. Note that these two statements are, in a sense, stating the same condition: if activity of different neurons is tightly correlated, their dynamics is concentrated on a low-dimensional plane and vice-versa - concentration of dynamics onto a low-dimensional plane will be perceived as correlation in activity of different neurons. In turn, low dimensionality of the neural dynamics may be caused by different factors, including common input, small subset of command neurons driving the circuit, or even emergent property of a network. Low dimensionality of neural dynamics results in that the inference problem becomes underdetermined, i.e. there may exist directions in ${\bf w}_i$ along which connectivity is not constrained by neural activity data (i.e. directions orthogonal to the subspace of all observed neural activity configurations), or is poorly constrained. This, naturally, leads to ${\bf w}_i$ being poorly defined along these directions. The necessary condition for good correspondence between functional connectivity weights ${\bf w}_i$ and anatomical connectivity, therefore, is {\em full-dimensionality} of the observed set of neural configurations. In case of spontaneously firing system of neurons this condition is satisfied by many neuron-firings occurring independently, thus, allowing to fully sample all possible directions in ${\bf w}_i$.  Still, spontaneously active preparation by itself may fail to display sufficient degree of independence between firing of neurons due to low-dimensionality of observed activity space, e.g. because of emergent properties of the circuit. In that case necessary variety of independent neural activity patterns may be enforced by randomly activating subsets of neurons via ChR2 or glutamate uncaging.
% 
% We also note that the correlations induced by secondary and so on synaptic transmissions (such as when neuron $A$ results in firing of neuron $B$, which in turn results in firing by neuron $C$), are all properly resolved in GLM-fitting process via the so called explaining-away process. In other words, because we do not just identify correlations between neural firings with the functional connectivity weights $\w_{ij}$, but instead statistically fit a model of neural interactions, if found weights between neurons $A$ and $B$, and $B$ and $C$ are sufficient to explain the correlation between $A$ and $C$, the weight connecting $A$ and $C$ will not appear in the model - the correlation between $A$ and $C$ was ``explained away'' by correlations between $A$ and $B$, and $B$ and $C$. By this, the multi-synaptic firing patterns do not confuse our estimation process.
% 
% ADD SOME RAVINGS ABOUT PROPER/IMPROPER FUNCTIONAL CONNECTIVITY.
