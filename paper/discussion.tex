In this paper we develop a Bayesian approach for inferring functional connectivity in a population of spiking neurons imaged with calcium imaging. While similar problem of inferring functional connectivity from a set of simultaneous spike-train recordings had been previously addressed for micro-electrode techniques [\cite{Rigat06},XXX], and the problem of inferring spikes of individual neurons from calcium imaging data had been addresses before [\cite{Vogelstein2009},XXX], we are the first to combine these two approaches to solve the problem of inferring functional connectivity from calcium imaging data. Because calcium imaging, in principle, has capacity to image populations of cells containing $\sim 1,000-100,000$ neurons, this opens the way for analysis of micro-circuitry in large and complete populations of neurons in neo-cortex or other brain areas.

$\ll$LIAM: Another discussion point: we'll want to discuss the work by fabio rigat
specifically: http://ba.stat.cmu.edu/journal/2006/vol01/issue04/rigat.pdf, \cite{Rigat06}
\newline they touched on a lot of similar themes: they stress the importance of the prior on the inference (they use a more complicated hierarchical prior for the network structure), they use a bernoulli glm as the foundation of their model, they develop a model to deal with misclassified spikes (they're dealing with noisy multielectrode recordings, but the issues are qualitatively similar to ours), and they end up using metropolis-within-gibbs as their main computational tool.
definitely worth checking out if you haven't read this before; we should be careful to cite them where appropriate in the main text, and also discuss the overlap in the discussion.

\noindent YURIy: I am not familiar with this work. J, if you can add something along the lines Liam wanted, please do, otherwise I put a cite to Rigat's paper above. $\gg$


The main challenge in this problem is indirect nature of calcium imaging data, which provides only noisy, low-pass nonlinear filtered, temporally sub-sampled observations of spikes of individual neurons. In order to find connectivity parameters, in Bayesian settings, the hidden spike-train variables need to be integrated out. Obtaining a joint sample of unobserved spike trains, needed to compute relevant integrals, is very non-trivial problem given high dimensionality of the hidden state if number of neurons, $N$, is large. In particular, methods for analyzing calcium imaging data for single neurons, \cite{Vogelstein2009}, do not generalize well for this application. To solve this problem, in this paper we develop a new method for obtaining samples from a collection of coupled low-dimensional HMMs by embedding sampling chains of states from individual low-dimensional HMM within a Gibbs sampler that loops in a predefined order over different coupled HMMs. The functional connectivity matrix is then inferred by maximizing the expected value of posterior log-likelihood in EM framework. Exponential prior is used to enforce sparseness condition of the objective connectivity matrix, which allows to significantly reduce the minimal amount of data required for successful reconstruction.

By applying this method to observations of spontaneous activity in a simulated population of neurons, we can efficiently infer the functional connectivity matrix from only $\sim 10$ min of simulated calcium imaging data (c.f Figure \ref{fig:recvar-SNR}, \ref{fig:recvar-NT}).
While embedded-chain-within-Gibbs methods leads to exact locally MAP estimate, under reasonable calcium imaging conditions we find that significant simplification is possible, where the posterior distribution may be assumed to approximately factorize, $P(\bX|\bF;\theta)\approx \prod P(X_i|F_i;\tilde\theta_i)$. This allows obtaining samples of joint spike trains $\bX$ much more easily and in parallel. Since the maximization procedure in EM also can be straightforwardly parallelized, thanks to special structure of the posterior likelihood, the entire inference method can be easily implemented as a highly parallelized application, offering significant savings in data-processing time.
If calculations are performed on a large high-performance cluster, reconstruction of the connectivity matrix from $\sim 10$ minutes of calcium imaging data can be performed nearly in real time, by solving each neuron on a separate node and utilizing only about $10$ minutes of computational time per each node. This is an important virtue of our method.

%And while our estimates exhibit some scale error (c.f. Figure \ref{fig:scatters}), the scale error is explained by the poor temporal resolution inherent in the data (c.f. Figure \ref{fig:bias}).  These results depend on a few theoretical advancements.  First, we develop an embedded-chain-within-blockwise-Gibbs algorithm for jointly sampling spike trains, given the calcium traces. Then, we show that by factorizing, we can obtain approximately equally good estimates (c.f. Figure \ref{fig:scatters}), which greatly expedites the computations.  Finally, we can impose a sparse prior on the connection matrix, justified by recent experimental findings \cite{Chlovksii}, to reduce the amount of observations necessary to obtain good estimates (c.f. Figure \ref{fig:sparse} and \ref{fig:distros}).  And while our approach breaks down in the face of strong correlations (c.f. Figure \ref{fig:rasters}), the algorithm fairs well under certain model misspecifications (c.f. Figure \ref{fig:vartau}).

Our method allows to measure functional connectivity conditioned on the spike trains of all observed neurons, i.e., $(\bn_1,\bn_2 | \bn_3, \ldots, \bn_N)$ \cite{emory, liam, Garofalo, Vakorina, etc.}. This differs significantly from previous works [XXX], which naively defined functional connectivity as a function of spike trains of only two neurons, $(\bn_i,\bn_j)$  - correlation coefficient, lagged cross-correlation, transfer entropy, or Granger causality. Since these measures explicitly ignore the spike trains of all other neurons, they suffer from the problems related to  ``third-neuron-mediated-interactions''. Specifically, if neuron $i$ and neuron $j$ both are strongly connected to third neuron $k$, such naive measures may report strong functional connection between neurons $i$ and $j$, even in the presence of observations of neuron $k$. Our method has added power of resolving such mediated interactions, or ``explaining away'': if correlation between neuron $i$ and neuron $j$ may be successfully modeled by functional connection with the third neuron $k$, our method will ``explain away'' such correlation, and assign to neurons $i$ and $j$ functional connection weight zero. 
We show that under certain condition (weak correlation among spike trains, c.f. Figure \ref{fig:sparse}) our method allows reconstructing true, ``anatomical'', connectivity matrix for the population of neurons solely from the activity data. At the same time, we demonstrate that under certain conditions such reconstruction from activity data alone may fail: if the spike trains are strongly correlated, functional connectivity matrix may not correspond to the true connectivity of the population even when all neurons are observed (c.f. Figure \ref{fig:rasters}). Such failure can be explained by inability of monitoring neural activity in strongly correlated spike trains to properly sample the space of all activity patterns, necessary to reliably constrain $\bw$.

%Importantly, the above-described approach for learning a functional connection matrix differs significantly from previous work.  Naively, one can define functional connectivity between a pair of neurons as some function of their two spike trains, $f(\bn_1,\bn_2)$.  Examples of such functions include correlation coefficient, lagged cross-correlation, transfer entropy, and Granger causality.  These measures are problematic, in that they implicitly ignore the spike trains of all other neurons.  One would rather have a measure of connectivity that is conditioned on the spike trains of all observable neurons, i.e., $f(\bn_1,\bn_2 | \bn_3, \ldots, \bn_N)$.  Several groups have recently developed methods to infer pairwise connectivity conditioned on all other observable spike trains \cite{emory, liam, Garofalo, Vakorina, etc.}.  To our knowledge, however, this work represents the first attempt to infer connectivity given some data other than spike trains.  As the spikes contain all the information about connectivity, we therefore must infer the spike trains first, and then estimate the functional connectivity.

In the view of these achievements and failures, a number of possible improvements of our method can be proposed. One of the biggest challenges for inferring neural connectivity from functional data is the presence of so called hidden inputs from unobserved neurons [XXX]. Since it is typically impossible to expect that activity of all neurons in a closed neural circuit can be monitored, such hidden inputs should be always anticipated in the real imaging data. Correlations in hidden inputs are capable of successfully mimicking functional connections among different observed neurons [XXX], thus presenting a substantial challenge for estimating neural circuit's connectivity from activity observations alone. Developing methods to cope with such hidden inputs is currently area of active research \cite{Duane 1 and 2, liam}.  Incorporating these features into our model is an important direction for future work.
Along with investigation of ways to combat the effect of unobserved neurons, we have considered several other potential directions for future improvements of our method.  Incorporating photo-stimulation to activate or deactivate individual neurons or their sub-populations may be used to significantly increase statistical power of a given set of observations. Especially, such external probes of neural network may be helpful in the case where the natural activity of a circuit results in strongly correlated firing patterns [Rafa?]. Although naturally observed behavior may not allow reliable determination of circuit's connectivity matrix, by utilizing external stimulation a sufficiently rich sample of activity patterns may be collected, and true anatomical structure of the neural circuit may be inferred. Developing the optimal sequences of artificial stimuli and their implementation in the actual experiments are other important directions for future work.

Furthermore, improvements of the algorithms for faster sampling spike trains from calcium imaging data, as well as for faster log-likelihood maximization may be possible [fast-filter?]. In particular, improvement in the spike-sampling algorithms for explicitly taking into account Poisson statistics of the spike counts in time-bins with large width, $\Delta$, rather than Bernoulli distribution used in this work, will be interesting. Modifications of our generative model allowing to deal with fluorescent signal non-stationarities, e.g. due to dye bleaching, and complicated effects in the dynamics of calcium concentration during spikes will be important to reliably apply our method to real imaging data.
Finally, a fully Bayesian algorithm for estimating the posterior distributions of all the parameters, as opposed to only finding the MAP estimate, is of great interest. Such fully-Bayesian extension is conceptually simple: we just need to extend this work's Gibbs sampler to additionally sample from $\theta$ given the spike trains $\bX$. Since we already have a method for drawing the spike trains $\bX$ given $\theta$ and $\bF$, with such additional sampler we may obtain samples from $P(\bX,\theta|\bF)$ simply by sampling from $\bX \sim P(\bX|\theta,\bF)$ and $\theta \sim P(\theta|\bX)$ within Gibbs sampling procedure.  Sampling from the posteriors $P(\theta|\bX)$ in the GLM setting is tractable using hybrid Monte Carlo methods, since all the posteriors are log-concave \cite{Ishwaran99,Gamerman97,Gamerman98,Yashar08}.

All these advances are currently being pursued.

%Possible improvements: Bayesian estimate of parameters; estimate of strongly correlated networks

%While this strategy captures the pairwise dependency between neurons, conditioned on all the other observable spike trains, it is often the case that many unobservable neurons are impacting the spike train statistics.  

%Along with coping with unobserved neurons, we have considered several other potential directions.  First, incorporating photo-stimulation to activate or deactivate small subpopulations of neurons to reduce the uncertainty of our estimates could potentially significantly reduce the amount of experimental time required to obtain a particular $r^2$ value.  Second, a fully Bayesian algorithm, estimating distributions of all the parameters (necessitating establishing priors on each), as opposed to only finding the maximum a posteriori (MAP) estimate, would be desirable.  Third, certain adaptations of this approach might be necessary to apply these algorithms to real data, including dealing with multiple spikes per frame, non-stationarities (e.g., bleaching), etc.  All these advances are currently being pursued.

%the extension to fully-bayesian methods is conceptually simple: we just need to extend our gibbs sampler to sample from theta given the spike trains; we already have a method for drawing the spike trains given theta and F.  sampling from the posteriors in the glm setting is very tractable using hybrid monte carlo methods, due to the log-concavity of the posteriors: we can cite the following related work here.

%Ishwaran99 {Applications of hybrid {Monte Carlo to Bayesian} generalized linear models: quasicomplete separation and neural networks}, Gamerman97, {Sampling from the posterior distribution in generalized linear mixed models}, Gamerman98, {Markov Chain Monte Carlo for Dynamic Generalised Linear Models}, Yashar08, {Efficient {Markov Chain Monte Carlo} methods for decoding population spike trains.},



\comment{
\paragraph{j's outline of discussion}

\begin{itemize}
\item summary of main point: using sparse prior, we can recover a large fraction of variance of connection weights, assuming reasonable SNR, parameters, and imaging rate.
\item $h_j$ vs. $h_{ij}$ reduces dimensionality of hidden space to $O(N)$ vs. $O(N^2)$, leading to our approach scaling well as $N \rightarrow$ big
\item $P(A|BC)\neq P(A|B)P(A|C)$ unless $B$ and $C$ are uncorrelated.  we use this property, correlation coefficient doesn't, cross-correlations, etc., do not.
\item for the same reason, hidden neurons might be a problem for us.  faster imaging, etc., should help alleviate that.
\item we can measure uncertainty in estimates, and use photo-stimulation to activate/deactivate small groups of neurons efficiently to help reduce variance in uncertainty.
\item certainly the issue of common input and unobserved neurons should be addressed a bit more in the discussion.
\item we can also talk a bit more about future directions involving fully-bayesian inference of the parameters (ie, MCMC over the parameter space, not just over the hidden variables X) instead of the MAP approach we took here; i tried to set this up a bit in the methods.
\item other important future work to mention: real data, faster mcmc sampling methods, dealing with nonstationarities (e.g. bleaching).
\item comparison with other work (e.g., duane's, Garofalo, Vakorina, transfer entropy, granger causality, etc.)
\end{itemize}
}
% \paragraph{scale bias discussion}
%
% Scale bias in principle may be removed by performing inference of the spike trains with the bin size $\Delta \rightarrow 0$. However, we were not successful in performing this calculation. One problem that we encountered with this approach was the increase in the variance of the connectivity estimates. In Eq.(\ref{eqn:likelihoodGLMmodb}) the coincident time bin $t=t'$ was omitted from the sum and so all spike pairs within the same time-bins were removed from the GLM fit. Because time position of such spike pairs inferred from fluorescence data typically would have inaccuracy $\approx \Delta$, temporal order of such spike pairs could often be confused, introducing ambiguity as to whether observed event should contribute to $w_{ij}$ or $w_{ji}$.
%
% Really, if the number of spikes of one neuron following that of another neuron within $\Delta$ was $n(2\rightarrow 1)$, while such in the reverse order was $n(1\rightarrow 2)$, difference $\delta n_{12} = n(2\rightarrow 1)-n(1\rightarrow 2)$ would correspond to the difference of functional connectivity weights $\delta w_{12}=w_{12}-w_{21}$. However, when such spike pairs had had their order confused with large probability $p\approx 1/2$, the number of spike pairs $n(2\rightarrow 1)$ actually observed would become $(1-p) n(2\rightarrow 1)+p n(1\rightarrow 2)$, and similarly for the reverse. Empirically observed difference $w_{12}-w_{21}$ thus would correspondingly drop to $\delta w'_{12}= (1-2p)\delta w_{12}$, while the variance would remain the same. This effect complicated estimating of the functional connectivity matrix $W$ by effectively mixing $\w_{12}$ and $\w_{21}$ and introducing large error in $W$ estimates, moving them toward $(W+W^T)/2$.
% We observed that the amount of data necessary to overcome this noise due to disordering of closely positioned spike-pairs appeared to be well over $\approx 10$ min of data used for the most of the calculations shown in this section below. Such high-time-resolution samples of spike trains also were substantially more computationally expensive to obtain and work with. For these reasons, we did not pursue this line of research further, although it may be of interest in the future.


% \paragraph{y's mini-discussion}
%
% Functional connectivity may fail to faithfully represent anatomical circuit structure if false correlations are present between different neurons, induced e.g. by common inputs, or if the dynamics of neural population is entirely concentrated on a low-dimensional subspace of the full configurational space ${\bf n}$. Note that these two statements are, in a sense, stating the same condition: if activity of different neurons is tightly correlated, their dynamics is concentrated on a low-dimensional plane and vice-versa - concentration of dynamics onto a low-dimensional plane will be perceived as correlation in activity of different neurons. In turn, low dimensionality of the neural dynamics may be caused by different factors, including common input, small subset of command neurons driving the circuit, or even emergent property of a network. Low dimensionality of neural dynamics results in that the inference problem becomes underdetermined, i.e. there may exist directions in ${\bf w}_i$ along which connectivity is not constrained by neural activity data (i.e. directions orthogonal to the subspace of all observed neural activity configurations), or is poorly constrained. This, naturally, leads to ${\bf w}_i$ being poorly defined along these directions. The necessary condition for good correspondence between functional connectivity weights ${\bf w}_i$ and anatomical connectivity, therefore, is {\em full-dimensionality} of the observed set of neural configurations. In case of spontaneously firing system of neurons this condition is satisfied by many neuron-firings occurring independently, thus, allowing to fully sample all possible directions in ${\bf w}_i$.  Still, spontaneously active preparation by itself may fail to display sufficient degree of independence between firing of neurons due to low-dimensionality of observed activity space, e.g. because of emergent properties of the circuit. In that case necessary variety of independent neural activity patterns may be enforced by randomly activating subsets of neurons via ChR2 or glutamate uncaging.
%
% We also note that the correlations induced by secondary and so on synaptic transmissions (such as when neuron $A$ results in firing of neuron $B$, which in turn results in firing by neuron $C$), are all properly resolved in GLM-fitting process via the so called explaining-away process. In other words, because we do not just identify correlations between neural firings with the functional connectivity weights $\w_{ij}$, but instead statistically fit a model of neural interactions, if found weights between neurons $A$ and $B$, and $B$ and $C$ are sufficient to explain the correlation between $A$ and $C$, the weight connecting $A$ and $C$ will not appear in the model - the correlation between $A$ and $C$ was ``explained away'' by correlations between $A$ and $B$, and $B$ and $C$. By this, the multi-synaptic firing patterns do not confuse our estimation process.
%
% ADD SOME RAVINGS ABOUT PROPER/IMPROPER FUNCTIONAL CONNECTIVITY.
