In order to sample spike train of a neuron from the imaged population, the spike train may be drawn over the set of particle swarms generated in the forward pass of the particle filter abov using a variant of finite forward-backward procedure.  Such procedure, however, is known to result in biased samples \cite{Andrieu2007, NBR03}.
Specifically, such samples are distributed with the probability density

\begin{align}
X_i &\sim \frac{1}{Z(G)} P(X_i(t=1)|{\bf X}_{\i}; W)\prod\limits_{t=2}^{T}P(X_i(t)|X_i(t-1), {\bf X}_{\i}; W) \prod_{t=1}^{T} P(F_i(t)|X_i(t); M_i) \\
Z(G) &= \sum_{\{X_i(t)\}\in G} P(X_i(t=1)|{\bf X}_{\i}; W) \prod_{t=2}^{T-1}P(X_i(t)|X_i(t-1), {\bf X}_{\i}; W) \prod_{t=1}^{T}P(F_i(t)|X_i(t); M_i).
\end{align}

\noindent where $G=\prod\limits_t G(t)$ is the collection of particle swarm samples $G(t)=\{X_i^{(l)}(t), X_i^{(l)}(t) \sim P(X_i(t)|\{{\bf X}_{\i}(t'),t'=1\ldots t\},\{{\bf F}(t'),t'=1\ldots t\};\theta)$, as constructed during the forward pass of the particle filter.  In particular, such probabilities of different sequences differ from the true probabilities by the difference in the estimated normalization constant $Z(G)$ from the true normalization $Z$.  This bias may be removed by embedding SMC into a larger importance sampling algorithm, correcting for bias $Z(G)$ by retaining SMC samples with probability $\sim Z(G)$ \cite{Andrieu2007}. In particular, Andrieu et al. \cite{Andrieu2007} show that as the size of the particle swarm grows the acceptance ratio of such importance sampling tends to unity.

A different and somewhat simpler approach, developed by Neal et al. \cite{NBR03}, is to use Markov Chain Monte Carlo method (MCMC) with the Markov chain constructed specifically to have the necessary equilibrium distribution $P(X_i| {\bf F}; \theta)$. The Markov Chain is constructed as follows. First, continuous-state HMM is replaced with a discrete HMM on a grid of points $G=\prod G(t)$, where $G(t) = \{X_i^{(l)}(t), l=1\ldots L\}$, $X_i^{(l)}(t)\sim \rho^i_t(X_i(t))$. I.e., at each time-point $t$ we define a pool of $L$ grid-points $\{X_i^{(l)}(t)\}$ drawn independently from a given proposal density $\rho^i_t(X_i(t))$. The grid $G$ is then constructed as a direct product of such pools.

Second, sequence of states is selected over such grid with the probability

\begin{equation}\label{eqn:nealprob}
X_i\sim P(X_i(t=1)|{\bf n}_{\i}; W)\prod\limits_{t=2}^{T-1}P(X_i(t)|X_i(t-1), {\bf X}_{\i}; W) \prod\limits_{t=1}^{T}
\frac{P(F_i(t)|X_i(t); M_i)}{\rho^i_t(X_i(t))}.
\end{equation}

This may be done directly and efficiently using forward-backward procedure with the observation probability modified to $P(F_i(t)|X_i(t), M_i)\rightarrow P(F_i(t)|X_i(t), M_i)/{\rho^i_t(X_i(t))}$.

Finally, states from the chosen sequence of states $X_i$ should be included in the pools $G(t)$ for the next MCMC step, $X_i(t)\in G(t)$, and the above two steps should be repeated with the new grid $G$. It is shown in \cite{NBR03} that the limiting distribution of such Markov chain is the correct unbiased distribution

\begin{equation}
P(X_i(t=1)|{\bf n}_{\i}, W)\prod\limits_{t=1}^{T-1}P(X_i(t)|X_i(t-1), {\bf X}_{\i}; W)\prod\limits_{t=1}^{T}P(F_i(t)|X_i(t); M_i).
\end{equation}

The advantage of Neal's method is that the grids $G$ are simple to prepare and also that no importance sampling rejection step is required - such step is implicitly accommodated in the forward-backward procedure via modified observation probability Eq. \eqref{eqn:nealprob}.

Proposal density $\rho^i_t(X_i(t))$ may be chosen arbitrary as long as it has sufficiently large support.  In order to achieve faster convergence, we use marginal densities $P(X_i(t)|{\bf X}_{\i}, \bf F; \theta)$ computed from the filter and smoother passes of the conventional SMC algorithm. Such accurate $\rho^i_t(X_i(t))$ allows the Markov Chain to converge extremely quickly.  $\rho^i_t(X_i(t))$ were constructed using kernel density estimation such that $\rho^i_t(C_i(t))$ was a mixture of Gaussians centered on particles from the particle swarm $C_i^{(l)}(t)$ with the variances $\approx var\left[C_i^{(l)}(t)-C_i^{(l')}(t) \right]$. $\rho^i_t(n_i(t))$ was taken to be Bernoulli distribution with the spike probability estimated from the particle swarm. Finally, $\rho^i_t(X_i(t)) = \rho^i_t(n_i(t)) \rho^i_t(C_i(t))$.  Such spike train samples for single neurons from the conditional probability distributions $P(X_i|{\bf X}_{\i}, \bf F; \theta)$ may be subsequently used in block-Gibbs sampling procedure to acquire joint sample from $P({\bf X}| {\bf F}; \theta)$ for a large number of coupled individual neuron HMM exactly and efficiently.  Specifically, we repeat the MCMC procedure to sample blocks of one neuron state-sequence at a time $X_i\sim P(X_{i}|{\bf X}_{\i},{\bf F}; \theta)$ sequentially for all neurons $i=1\ldots N$ for $N_G$ Gibbs cycles.  We accumulate samples at the end of each of $N_G$ cycles.

A substantial simplification may occur if SNR in the calcium imaging data is high. In this case, the posterior distribution for neural states is dominated by the fluorescence term $P(X_i|{\bf X}_{\i},{\bf F};\theta)\approx P(X_i|F_i;M_i)$. If that is the case, then the joint distribution for ${\bf X}$ approximately factorizes into a product of $F_i$-dependent posterior distributions for different neuron, $P({\bf X}|{\bf F};\theta)\approx\prod_i P(X_i|F_i; M_i)$. Such factorization allows to produce the sample ${\bf X}$ much easier, in particular, because the sample of spike trains for each neuron is independent on the states of the other neurons given $F_i$. $X_i\sim P(X_i|F_i;M_i)$, therefore, may be obtained separately for different neurons using the alrogithm described above. Joint sample from $P({\bf X}|{\bf F};\theta)$, then, is simply obtained as the combination of independent samples ${\bf X}=(X_1,\ldots,X_N)$.
Note, that since by assumption individual samples $X_i\sim P(X_i|F_i;M_i)$ do not depend on the states of other neurons, in this case the GLM solution $W$ is obtained after single iteration of the full algorithm \ref{eqn:pseudocode}, because in the subsequent iterations the sample of spike trains ${\bf X}$ never changes.

We refer to such procedure for estimating the functional connectivity matrix as independent approximation. Depending on the accuracy of such approximation, it may or may not be acceptable for the estimation of the true functional connectivity matrix $W$. However, as we show below, it is indeed the case that the independent approximation is adequate here for interesting calcium imaging SNR regimes.

The MCMC-Gibbs procedure for sampling joint spike trains above allows one to obtain samples of ${\bf n}\sim P({\bf n}|{\bf F}; \bth)$ from a high-dimensional HMM. However, if the temporal structure of the functional connection weights $w_{ij}(t)$ is known in advance, e.g. if $w_{ij}(t)=w_{ij}\exp(-t/\tau_w)$, drawing spike train samples from $P({\bf X}|{\bf F};\bth)$ may be avoided by introducing reduced history variables 
\begin{equation}
h_i(t)=\sum\limits_{t'<t} n_i(t')\exp(-(t-t')/\tau_w).
\end{equation}
In terms of $h_i(t)$ GLM likelihood may be written as follows, 
\begin{equation}
E[\ln P_{\bn}(n_i|{\bf h}; W)]\approx \sum_t \left(\sum\limits_{j} w_{ij} E[n_i(t) h_j(t)] -
E[(1-n_i(t)) \exp\left(\sum\limits_j w_{ij}h_j(t)\right)] \Delta \right). 
\end{equation}
i.e. the GLM likelihood in terms of reduced history variables factorizes over time $P_{\bn}(n_i|{\bf h};W)=\prod_t P_{\bn}(n_i(t)|{\bf h}(t);W)$.
Then, GLM parameters may be estimated using only the marginal distributions $P({\bf n}(t), {\bf h}(t)|{\bf F};\bth)$ without drawing the full spike train samples ${\bf n}$.

Reduced history variables provide substantial simplification over full MCMC procedure. In particular, when such history variables may be constructed via a Markov process, e.g.
\begin{equation}\label{eqn:spkhist:definition}
h_i(t)=(1-\Delta/\tau_w) h_i(t-1) + n_i(t-1) + \epsilon_i(t), 
\end{equation}
($\epsilon_i(t)$ is normally distributed internal noise term with variance $\sigma^2_h$) samples from marginal distributions necessary for E-step may be found using SMC method. In particular, if the time-history of the  functional connection weights may be decomposed into a linear sum of  terms with exponential time-dependence with different decay times, such Markov process construction Eq. \eqref{eqn:spkhist:definition}), obviously, is always possible using reduced history vector $h_i^{(l)}(t)$, each $h_i^{(l)}(t)$ governed by a different time-constant $\tau^{(l)}_w$. GLM parameters may be estimated from marginal distributions $P({\bf n}(t), \{{\bf h}^{(l)}(t)\}|{\bf F};\bth)$.  Such formulation of GLM inference problem is completely equivalent to the above formulation operating with the full spike train samples ${\bf X}$, and may be used fully interchangeably with it. Given better computational cost of computing marginal distributions $P({\bf n}(t), {\bf h}(t)|{\bf F};\bth)$, in suitable conditions this approach may be extremely advantageous. 

