In specific implementation of the above EM algorithm, we break the inference problem into three steps (see algorithm \ref{eqn:pseudocode}).  First, we estimate for each neuron $i$ the model of its calcium dynamics $M_i$, given observations $F_i$ and the currents $J_i(t)=b_i+\sum_{j}\sum_{t'<t}w_{ij}(t-t')n_{j}(t')$ from the previous EM estimate of $w_{ij}(t)$, $b_i$ and $n_{j}(t)$ (at first iteration $w_{ij}(t) \equiv 0$), on a subset of data with $\sim 10-100$ spikes.  It is advantageous to perform estimation of $M_i$ separately because this problem may be solved using smaller amount of data ($\sim 10-100$ spikes). Since estimation of $W$ requires processing very large amounts of data ($\sim 1000-3000$ spikes), pre-estimating $M_i$ allows to arrive quicker at a better estimate of $W$ at a lower computational cost.  Second, using thus produced calcium dynamics models $M_i$, we obtained a joint sample of spike-histories $\{ n_i(t)\}$ using hybrid MCMC-Gibbs or SMC method above.  In this work we accounted for the impact of interactions with other neurons via injected currents $J_i(t)$, which thus accounted for the information about the past neural activity in the population only - $n_i(t) \sim P(n_i(t)|{\bf n}(t'), {t'=1\ldots t-1})$. In principle, better samples could be obtained by taking into account spiking of the other neurons at $t'>t$, i.e. sampling from $P(n_i(t)|{\bf n}(t'), {t'=1\ldots T})$ \cite{PL07}. Such improved sampling procedure is a subject of future effort.  Reduced history variables $\{h_i(t)\}$ were also computed at the time of obtaining spike samples.  Third, given joint spike train samples $\{ n_i(t)\}$ or samples of reduced history variables $\{ h_i(t)\}$, we performed estimation of the functional connectivity matrix $W$ by solving large convex optimization problem.  Steps one through three were then repeated until convergence in the functional connectivity weights $W$ was observed.

Important feature of the above algorithm is that the above procedures straightforwardly parallelize. Estimation of models $M_i$ could be done independently for all neurons. Calculation of the functional connectivity matrix $W$ also involved solving $N$ optimization sub-problems for different neurons that could be done independently. In independent approximation, sample $\{ n_i(t)\}$ could be obtained in parallel for different neurons; while for hybrid MCMC-Gibbs method obtaining the sample could be parallelized by drawing HMM state-sequences within Gibbs loop for a few neurons at a time, instead of single neuron at a time. High parallelizability of these steps resulted in significant time savings when analysis of calcium imaging data was performed on multi-processor computer or using a super-computing facility.  We performed bulk of the calculations on a high-performance cluster of Intel Xeon L5430 based computers (2.66 GHz). For 10 minutes of simulated fluorescence data, calculations typically took 10-20 minutes per neuron using independent approximation, with time split approximately equally between calcium model estimation and obtaining spike-history samples (5-10 min) and solving GLM problem (5-10 min). Hybrid MCMC-Gibbs sampler was substantially slower, up to an hour per neuron per Gibbs pass, with Gibbs sampler being the most computationally expensive part. Parallel computation made calculations for large populations of neurons $N\sim 200-500$ possible.
