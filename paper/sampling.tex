In order to sample spike train of a neuron from the imaged population, the spike train may be drawn over the set of particle swarms generated in the forward pass of the particle filter abov using a variant of finite forward-backward procedure.  Such procedure, however, is known to result in biased samples \cite{Andrieu2007, NBR03}.
Specifically, such samples are distributed with the probability density

\begin{align}
X_i &\sim \frac{1}{Z(G)} P(X_i(t=1)|{\bf X}_{\i}; W)\prod\limits_{t=2}^{T}P(X_i(t)|X_i(t-1), {\bf X}_{\i}; W) \prod_{t=1}^{T} P(F_i(t)|X_i(t); M_i) \\
Z(G) &= \sum_{\{X_i(t)\}\in G} P(X_i(t=1)|{\bf X}_{\i}; W) \prod_{t=2}^{T-1}P(X_i(t)|X_i(t-1), {\bf X}_{\i}; W) \prod_{t=1}^{T}P(F_i(t)|X_i(t); M_i).
\end{align}

\noindent where $G$ is XXX.  In particular, such probabilities of different sequences differ from the true probabilities by the difference in the estimated normalization constant $Z(G)$ from the true normalization $Z$.  This bias may be removed by embedding SMC into a larger importance sampling algorithm, correcting for bias $Z(G)$ by retaining SMC samples with probability $\sim Z(G)$ \cite{Andrieu2007}. In particular, Andrieu et al. \cite{Andrieu2007} show that as the size of the particle swarm grows the acceptance ratio of such importance sampling tends to unity.

A different and somewhat simpler approach, developed by Neal et al. \cite{NBR03}, is to use Markov Chain Monte Carlo method (MCMC) with the Markov chain constructed specifically to have the necessary equilibrium distribution $P(X_i| {\bf F}; \theta)$. The Markov Chain is constructed as follows. First, continuous-state HMM is replaced with a discrete HMM on a grid of points $G=\prod G(t)$, where $G(t) = \{X_i^{(l)}(t), l=1\ldots L\}$, $X_i^{(l)}(t)\sim \rho^i_t(X_i(t))$. I.e., at each time-point $t$ we define a pool of $L$ grid-points $\{X_i^{(l)}(t)\}$ drawn independently from a given proposal density $\rho^i_t(X_i(t))$. The grid $G$ is then constructed as a direct product of such pools.

Second, sequence of states is selected over such grid with the probability

\begin{equation}\label{eqn:nealprob}
X_i\sim P(X_i(t=1)|{\bf n}_{\i}; W)\prod\limits_{t=2}^{t=T-1}P(X_i(t)|X_i(t-1), {\bf n}_{\i}; W) \prod{t=1}^{T}
\frac{P(F_i(t)|X_i(t), M_i)}{\rho^i_t(X_i(t))}.
\end{equation}

This may be done directly and efficiently using forward-backward procedure with the observation probability modified to $P(F_i(t)|X_i(t), M_i)\rightarrow P(F_i(t)|X_i(t), M_i)/{\rho^i_t(X_i(t))}$.

Finally, states from the chosen sequence of states $X_i$ should be included in the pools $G(t)$ for the next MCMC step, $X_i(t)\in G(t)$, and the above two steps should be repeated with the new grid $G$. It is shown in \cite{NBR03} that the limiting distribution of such Markov chain is the correct unbiased distribution

\begin{equation}
P(X_i(t=1)|{\bf n}_{\i}, W)\prod\limits_{t=1}^{t=T-1}P(X_i(t)|X_i(t-1), {\bf n}_{\i}, W)\prod\limits_{t=1}^{t=T}P(F_i(t)|X_i(t), M_i).
\end{equation}

The advantage of Neal's method is that the grids $G$ are simple to prepare and also that no importance sampling rejection step is required - such step is implicitly accommodated in the forward-backward procedure via modified observation probability Eq. \eqref{eqn:nealprob}.

Proposal density $\rho^i_t(X_i(t))$ may be chosen arbitrary as long as it has sufficiently large support.  In order to achieve faster convergence, we use marginal densities $P(X_i(t)|{\bf X}_{\i}, \bf F; \theta)$ computed from the conventional SMC algorithm. Such accurate $\rho^i_t(X_i(t))$ allows the Markov Chain to converge extremely quickly.  $\rho^i_t(X_i(t))$ were constructed using kernel density estimation such that $\rho^i_t(C_i(t))$ was a mixture of Gaussians centered on particles from the particle swarm $C_i^{(l)}(t)$ with the variances $\approx var\left[C_i^{(l)}(t)-C_i^{(l')}(t) \right]$. $\rho^i_t(n_i(t))$ was taken to be Bernoulli distribution with the spike probability estimated from the particle swarm. Finally, $\rho^i_t(X_i(t)) = \rho^i_t(n_i(t)) \rho^i_t(C_i(t))$.  Such spike train samples for single neurons from the conditional probability distributions $P(X_i|{\bf X}_{\i}, \bf F; \theta)$ may be subsequently used in block-Gibbs sampling procedure to acquire joint sample from $P({\bf X}| {\bf F}; \theta)$ for a large number of coupled individual neuron HMM exactly and efficiently.  Specifically, we repeat the MCMC procedure to sample blocks of one neuron state-sequence at a time $X_i\sim P(X_{i}|{\bf X}_{\i},{\bf F}; \theta)$ sequentially for all neurons $i=1\ldots N$ for $N_G$ Gibbs cycles.  We accumulate samples at the end of each of $N_G$ cycles.

A substantial simplification may occur if SNR in the calcium imaging data is high. In this case, the posterior distribution for neural states is dominated by the fluorescence term $P(X_i|*)\approx P(X_i|F_i)$, XXX i don't understand what the $\ast$ is a placeholder for XXX and the joint distribution for ${\bf X}$ approximately factorizes $P({\bf X}|\bth, {\bf F})\approx\prod P(X_i|F_i, M_i)$. If this factorization is sufficiently accurate, the sample of ${\bf X}$ may be obtained by independently drawing state-sequences for single neurons $X_i \sim P(X_i|F_i, M_i)$ and then combining them to form the joint sample ${\bf X}$.  We refer to such samples as the independent approximation. Depending on the accuracy of such approximation, it may or may not be acceptable for the estimation of functional connectivity matrix $W$ from the calcium imaging data. However, as we show below, it is indeed the case that the independent approximation is adequate here for interesting calcium imaging SNR regimes.

The MCMC-Gibbs procedure for sampling joint spike trains above allows one to obtain samples of ${\bf n}\sim P({\bf n}|{\bf F}; \bth)$ from a high-dimensional HMM. However, if the temporal structure of the functional connection weights $w_{ij}(t)$ is known in advance, e.g. if $w_{ij}(t)=w_{ij}\exp(-t/\tau_w)$, drawing spike train samples from $P({\bf X}|\bth, {\bf F})$ may be avoided by using marginal distributions of the reduced history variables $P({\bf h}(t)|\bth, {\bf F})$, 

\begin{equation}
h_i(t)=\sum\limits_{t'<t} n_i(t')\exp(-(t-t')/\tau_w).
\end{equation}
In terms of $h_i(t)$ GLM likelihood may be written as follows, 
\begin{equation}
E[\log P_{GLM}(n_i|{\bf h}, W)]\approx \sum_t \left(\sum\limits_{j} w_{ij} E[n_i(t) h_j(t)] -
E[(1-n_i(t)) \exp(\sum\limits_j w_{ij}h_j(t))] \Delta \right), 
\end{equation}

so that GLM parameters may be estimated from the marginal distributions $P({\bf n}(t), {\bf h}(t)|\bth, {\bf F})$ without drawing the full spike train samples ${\bf n}$.

Using reduced history variables provides substantial simplification over full MCMC procedure. In particular, such history variables may be constructed via Markov process

\begin{equation}\label{eqn:spkhist:definition}
h_i(t)=(1-\Delta/\tau_w) h_i(t-1) + n_i(t-1) + \epsilon_i(t), 
\end{equation}

where $\epsilon_i(t)$ is additional normally distributed internal noise term with variance $\sigma^2_h$, and so their marginal distributions may be estimated using above particle filter method. If the time-history of the  functional connection weights may be represented as a linear combination of few exponentials with different decay times, Eq. \eqref{eqn:spkhist:definition}) may be obviously generalized to this case to also use multiple reduced history variables $h_i^{(l)}(t)$, each with a different time-constant $\tau^{(l)}_w$, in order to represent such more complex time-dynamics, allowing estimating GLM parameters from marginal distributions $P({\bf n}(t), \{{\bf h}^{(l)}(t)\}|\bth, {\bf F})$.  Such formulation of GLM inference problem is completely equivalent to the above formulation operating with the full spike train samples ${\bf X}$, and may be used fully interchangeably with it. Given better computational cost of computing marginal distributions $P({\bf n}(t), {\bf h}(t)|\bth, {\bf F})$, in suitable conditions this approach may be extremely advantageous.