\relax 
\gdef \tocmax@section{21.41656pt}
\gdef \tocmax@subsection{15.12502pt}
\gdef \tocmax@subsubsection{12.2778pt}
\gdef \tocmax@paragraph{5.0pt}
\gdef \tocmax@appendix{5.0pt}
\gdef \tocmax@pagenum{5.0pt}
\citation{MichevaSmith07}
\citation{Brainbow07}
\citation{Briggman2006}
\citation{PILL07}
\citation{Tsien89}
\citation{Abeles91}
\citation{Braitenberg1998}
\citation{ImagingManual}
\citation{StosiekKonnerth03}
\citation{WallaceHasan08}
\citation{Djurisic04}
\citation{Iyer06}
\citation{ReddySaggau05}
\citation{ReddySaggau08}
\citation{SalomeBourdieu06}
\citation{NguyenParker01}
\newlabel{FirstPage}{{}{1}{}{}{}}
\@writefile{toc}{\tocdepth@munge}
\@writefile{toc}{\contentsline {section}{\numberline {}Contents}{1}{}}
\@writefile{toc}{\tocdepth@restore}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}}
\newlabel{intro}{{I}{1}{}{}{}}
\citation{DGL01}
\citation{Neal03}
\citation{BRIL88}
\citation{BRIL92}
\citation{CSK88}
\citation{KP06}
\citation{NYK06}
\citation{PAN04c}
\citation{PAN03d}
\citation{PILL07}
\citation{PG00}
\citation{Rigat06}
\citation{Stevenson2009}
\citation{TRUC05}
\citation{Vidne08}
\citation{PAN04c}
\citation{LD89}
\citation{PAN04c}
\citation{Escola07}
\@writefile{toc}{\contentsline {section}{\numberline {II}Methods}{2}{}}
\newlabel{sec:methods}{{II}{2}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Model}{2}{}}
\newlabel{sec:methods:markov-setup}{{II\tmspace  +\thinmuskip {.1667em}A}{2}{}{}{}}
\newlabel{eqn:glm:definition}{{1}{2}{}{}{}}
\citation{Vogelstein2009}
\citation{ImagingManual}
\citation{Vogelstein2009}
\citation{Yasuda2004}
\citation{Vogelstein2009}
\citation{Rigat06}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Expected firing vs. input to the neuron. Given our model, Eq. 1{}{}{}\hbox {}, the relationship between firing rate and the magnitude of the input to a neuron is highly nonlinear. Note that firing rate saturates at $1/\Delta $, because of our Bernoulli assumption.}}{3}{}}
\newlabel{fig:egfluor}{{1}{3}{}{}{}}
\newlabel{eqn:h:definition}{{3}{3}{}{}{}}
\newlabel{eqn:ca:definition}{{4}{3}{}{}{}}
\newlabel{eqn:F:definition}{{5}{3}{}{}{}}
\citation{DLR77}
\citation{McLachlanKrishnan96}
\citation{RAB89}
\citation{Vogelstein2009}
\citation{ShumwayStoffer06}
\citation{DFG01}
\citation{DGA00}
\citation{GDW04}
\citation{Vogelstein2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Goal and general strategy}{4}{}}
\newlabel{sec:methods:goal}{{II\tmspace  +\thinmuskip {.1667em}B}{4}{}{}{}}
\newlabel{eqn:loglik:definition-expl}{{6}{4}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Initialization of ``internal'' parameters via sequential Monte Carlo methods}{4}{}}
\newlabel{sec:methods:indep}{{II\tmspace  +\thinmuskip {.1667em}C}{4}{}{}{}}
\newlabel{eqn:forward}{{7}{4}{}{}{}}
\newlabel{eqn:backward}{{8}{4}{}{}{}}
\citation{BickelBengtsson08}
\citation{Andrieu2007}
\citation{NBR03}
\citation{NBR03}
\newlabel{eq:particle-fb}{{9}{5}{}{}{}}
\newlabel{eqn:bw}{{10}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Estimating joint posteriors over weakly coupled neurons}{5}{}}
\newlabel{sec:methods:joint}{{II\tmspace  +\thinmuskip {.1667em}D}{5}{}{}{}}
\citation{NBR03}
\citation{NBR03}
\citation{Vogelstein2009}
\citation{Binzegger04}
\citation{Buhl94}
\citation{Feldmeyer99}
\citation{FeldmeyerSakmann00}
\citation{Gupta00}
\citation{Mishchenko2009b}
\citation{PetersenSakmann00}
\citation{Reyes98}
\citation{Song2005}
\citation{Thompson88}
\citation{PAN04c}
\citation{PILL07}
\citation{Rigat06}
\citation{Stevenson08}
\citation{Candes2005}
\citation{DE03}
\citation{Mishchenko2009}
\citation{NG04}
\citation{Tibs96}
\citation{TIP01}
\citation{CONV04}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}A cheaper high-SNR approximation of the joint posteriors}{6}{}}
\newlabel{sec:cheaper-high-snr}{{II\tmspace  +\thinmuskip {.1667em}D\tmspace  +\thinmuskip {.1667em}1}{6}{}{}{}}
\newlabel{eqn:indep_approx}{{13}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}Estimating the functional connectivity matrix}{6}{}}
\newlabel{sec:methods:parameters HMM}{{II\tmspace  +\thinmuskip {.1667em}E}{6}{}{}{}}
\citation{Vogelstein2009}
\citation{Braitenberg1998}
\citation{Urquijo2000}
\citation{Lefort2009}
\citation{Sayer1990}
\citation{Braitenberg1998}
\citation{Urquijo2000}
\citation{Braitenberg1998}
\citation{Lefort2009}
\citation{Lefort2009}
\citation{Sayer1990}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1}Imposing a sparse prior on the functional connectivity}{7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2}Imposing Dale's law on the functional connectivity}{7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F}Specific implementation notes}{7}{}}
\newlabel{sec:methods:specific_implementation}{{II\tmspace  +\thinmuskip {.1667em}F}{7}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Results}{7}{}}
\newlabel{sec:results}{{III}{7}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Simulating neural activity in a neural population}{7}{}}
\newlabel{sec:results:simulations}{{III\tmspace  +\thinmuskip {.1667em}A}{7}{}{}{}}
\citation{Sayer1990}
\citation{Vogelstein2009}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Pseudocode for estimating functional connectivity from calcium imaging data using EM; $\eta ^n$, $\eta ^F$, $N_G$ are user-defined convergence tolerance parameters. XXX CAN WE INDENT THE BELOW PROPERLY? WOULD MAKE IT MORE LEGIBLE XXX}}{8}{}}
\newlabel{eqn:pseudocode}{{1}{8}{}{}{}}
\newlabel{eqn:convert}{{15}{8}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Inferring functional connectivity from the simulated calcium imaging data}{9}{}}
\newlabel{sec:results:inference}{{III\tmspace  +\thinmuskip {.1667em}B}{9}{}{}{}}
\newlabel{eqn:likelihoodGLMmoda}{{16}{9}{}{}{}}
\newlabel{eqn:likelihoodGLMmodb}{{17}{9}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Table of simulation parameters.}}{9}{}}
\newlabel{table:caparm}{{I}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Schematic overview. First we obtain large-scale calcium recordings of spontaneous and evoked neural responses. These movies are then pre-processed to correct for movement artifacts, find regions-of-interest, and extract spike trains. Second, given the fluorescence traces from each neuron, we infer spike trains. Third, we use our population model to infer the most likely functional connectivity matrix, which is our approximation of the microcircuit.}}{10}{}}
\newlabel{fig:egfluor}{{2}{10}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Scale bias in inferred connection weights due to coarse time discretization of calcium imaging data}{10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Functional connectivity matrix can be reconstructed from calcium imaging data. In the upper panels inferred connection weights are shown in a scatter plot versus real connection weights, with inference performed using independent approximation algorithm, exact MCMC-Gibbs algorithm, and original spike trains observed at the frame rate of the calcium imaging. Network of $N=25$ neurons was used, firing at $\approx 5$ Hz, and imaged for T=600 sec at intermediate SNR (photon budget 10Kph/neuron/frame, see below). $r^2=0.47$ for independent approximation algorithm was found, $r^2=0.48$ for MCMC-Gibbs algorithm, and $r^2=0.57$ for the original spike trains. Thus, independent approximation produced results almost as accurate as the exact MCMC-Gibbs algorithm, and almost as accurate as the original spikes. Inferred connectivity weights (upper left) were scaled with respect to true connectivity by a constant amount due to time discretization bias (see below); other than scale, inferred connectivity represented the true connectivity matrix very well (upper right). Thus, calcium imaging is sufficient to identify connected pairs of neurons reliably.}}{11}{}}
\newlabel{fig:scatters}{{3}{11}{}{}{}}
\newlabel{eqn:bias}{{18}{11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Low-frame rate of calcium imaging, leading to large bin size $\Delta \approx 15-30$ ms of the inferred spike trains, is the reason of scale bias in the estimated connectivity matrix. This bias is explained by considering what number of causally-related spikes from a pair of neurons occur within the same time-bin for bin size $\Delta $, and so are not considered as causally related but coincidental in the time-discretized spike trains.}}{11}{}}
\newlabel{fig:bias}{{4}{11}{}{}{}}
\citation{Vogelstein2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Impact of different imaging frame rates, durations, and noise levels on the inference}{12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Accuracy of the inferred connectivity weights as function of the frame rate of calcium imaging. Connectivity matrix here was inferred from the original spike trains observed at corresponding frame rates, thus establishing the upper performance bound for inference using calcium imaging data. A network of $N=25$ neurons, firing at $\approx 5$ Hz and imaged for $T=600$ sec was used.}}{12}{}}
\newlabel{fig:recvar}{{5}{12}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Accuracy of inferred connectivity weights as function of the noise amount in the calcium imaging data, as quantified by experimental photon budget per neuron-frame, for frame rates of 15 Hz, 33 Hz and 66 Hz. Photon counts on the order of 20-40 Kph/frame/neuron are required to achieve the upper bound due by the frame rate. Connectivity matrix here was inferred from simulated fluorescence data using independent approximation algorithm. . Simulation conditions are the same as in Figure 5{}{}{}\hbox {}.}}{13}{}}
\newlabel{fig:recvar-SNR}{{6}{13}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Accuracy of inferred connectivity weights as function of the imaging time and neural population size. Incorporating simple priors such as exponential prior on the connectivity weights allows to boost reconstruction accuracy dramatically (dashed lines). In this latter case, $T=300$ sec is already sufficient to recover 70\% of the variance in the connection weights. Incorporating Dale's prior leads to only marginal improvement (dotted line). As shown in the methods, reconstruction accuracy does not depend on the neural population size $N$. Here, neural population from $N=10$ to $N=200$ were simulated for different $T$, where $N=200$ (gray) and $N=100$ (black) are shown. All networks were prepared in similar state by adjusting strength of inhibitory connections to achieve similar mean firing rate $\approx 5$ Hz, although actual firing rate in these networks could vary. In all cases, $T=5$ min - 0.5 hour is sufficient to produce accurate reconstructions. }}{13}{}}
\newlabel{fig:recvar-NT}{{7}{13}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E}Accuracy of the estimates and Fisher information matrix}{13}{}}
\newlabel{sec:methods:accuracy_Fisher}{{III\tmspace  +\thinmuskip {.1667em}E}{13}{}{}{}}
\newlabel{eqn:fisher}{{20}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {F}Impact of using priors on the inference}{14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Incorporating simple priors on the distribution of connectivity weights in the Bayesian inference algorithm, such as exponential sparseness prior, is essential to achieve much more accurate reconstructions than using simple GLM from a smaller amount of calcium imaging data. Here, connection weights reconstructed using simple GLM (left panel) or sparse-prior GLM (right panel) are shown in a scatter plot for a network of $N=50$ neurons firing at $\approx 5$ Hz and imaged for $T=600$ sec. $r^2=0.64$ for simple GLM solution and $r^2=0.85$ for sparse-GLM solution.}}{14}{}}
\newlabel{fig:sparse}{{8}{14}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Distribution of inferred connection weights using simple GLM (left) and sparse GLM (right) vs true distributions. When sparse exponential prior on the distribution of connection weights is enacted, dispersion in inferred connection weights is substantially reduced and, in particular, it becomes possible to reliably determine which neural pairs are connected. Distributions are shown for a network of $N=200$ neurons firing at $\approx 5$ Hz and imaged for $T=600$ s was used here.}}{15}{}}
\newlabel{fig:distros}{{9}{15}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {G}Impact of strong correlations and deviations from generative model on the inference}{15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Discussion}{15}{}}
\newlabel{sec:discussion}{{IV}{15}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {a}j's outline of discussion}{15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  Diverseness of observed neural activity patterns is required for functional connectivity to give access to the actual ``anatomical'' structure of the neural circuit. Here, 15 sec of simulated spike trains for a weakly coupled network (upper-left) and a network with strongly coupled component (upper-right) are shown. In weakly coupled network spikes are sufficiently uncorrelated to give access to all different neural activity patterns needed to properly estimate true weights ${\bf  w}_i$. In strongly coupled case, many instances of highly synchronous locked firings are evident, thus preventing observation of sufficiently rich ensemble of activity patterns. Accordingly, GLM solution for the strongly coupled neural network (lower-right) does not represent the true connectivity of the circuit, even for the weakly coupled circuit's component. This is contrary to the weakly-coupled network (lower-left) where true connectivity is successfully estimated. Networks of $N=50$ neurons firing at $\approx 5$ Hz and imaged for $T=600$ sec were used to produce this figure.}}{16}{}}
\newlabel{fig:rasters}{{10}{16}{}{}{}}
\bibdata{mybib}
\bibcite{Abeles91}{{1}{}{{}}{{}}}
\bibcite{Andrieu2007}{{2}{}{{}}{{}}}
\bibcite{BickelBengtsson08}{{3}{}{{}}{{}}}
\bibcite{Binzegger04}{{4}{}{{}}{{}}}
\bibcite{CONV04}{{5}{}{{}}{{}}}
\bibcite{Braitenberg1998}{{6}{}{{}}{{}}}
\bibcite{Briggman2006}{{7}{}{{}}{{}}}
\bibcite{BRIL88}{{8}{}{{}}{{}}}
\bibcite{BRIL92}{{9}{}{{}}{{}}}
\bibcite{Buhl94}{{10}{}{{}}{{}}}
\bibcite{Candes2005}{{11}{}{{}}{{}}}
\bibcite{CSK88}{{12}{}{{}}{{}}}
\bibcite{DLR77}{{13}{}{{}}{{}}}
\bibcite{Djurisic04}{{14}{}{{}}{{}}}
\bibcite{DE03}{{15}{}{{}}{{}}}
\bibcite{DFG01}{{16}{}{{}}{{}}}
\bibcite{DGA00}{{17}{}{{}}{{}}}
\bibcite{Escola07}{{18}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Bayesian inference algorithm is robust to distortions of the underlying generative model. One distortion that should be expected is variability of the EPSP time courses from neuron to neuron, and possibly synapse to synapse. With up to 25\% variability allowed in EPSP time scales $\tau _w$ (right panel) our algorithm provided reconstructions of the same quality as when all $\tau _w$ were the same (left panel). Simulation conditions are the same as in Figure 5{}{}{}\hbox {}.}}{17}{}}
\newlabel{fig:vartau}{{11}{17}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {}Acknowledgements}{17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{17}{}}
\bibcite{Feldmeyer99}{{19}{}{{}}{{}}}
\bibcite{FeldmeyerSakmann00}{{20}{}{{}}{{}}}
\bibcite{GDW04}{{21}{}{{}}{{}}}
\bibcite{Urquijo2000}{{22}{}{{}}{{}}}
\bibcite{Gupta00}{{23}{}{{}}{{}}}
\bibcite{Iyer06}{{24}{}{{}}{{}}}
\bibcite{KP06}{{25}{}{{}}{{}}}
\bibcite{Lefort2009}{{26}{}{{}}{{}}}
\bibcite{LD89}{{27}{}{{}}{{}}}
\bibcite{Brainbow07}{{28}{}{{}}{{}}}
\bibcite{McLachlanKrishnan96}{{29}{}{{}}{{}}}
\bibcite{MichevaSmith07}{{30}{}{{}}{{}}}
\bibcite{Mishchenko2009}{{31}{}{{}}{{}}}
\bibcite{Mishchenko2009b}{{32}{}{{}}{{}}}
\bibcite{Neal03}{{33}{}{{}}{{}}}
\bibcite{NBR03}{{34}{}{{}}{{}}}
\bibcite{NG04}{{35}{}{{}}{{}}}
\bibcite{NguyenParker01}{{36}{}{{}}{{}}}
\bibcite{NYK06}{{37}{}{{}}{{}}}
\bibcite{PAN04c}{{38}{}{{}}{{}}}
\bibcite{PAN03d}{{39}{}{{}}{{}}}
\bibcite{PetersenSakmann00}{{40}{}{{}}{{}}}
\bibcite{PILL07}{{41}{}{{}}{{}}}
\bibcite{PG00}{{42}{}{{}}{{}}}
\bibcite{RAB89}{{43}{}{{}}{{}}}
\bibcite{ReddySaggau05}{{44}{}{{}}{{}}}
\bibcite{ReddySaggau08}{{45}{}{{}}{{}}}
\bibcite{Reyes98}{{46}{}{{}}{{}}}
\bibcite{Rigat06}{{47}{}{{}}{{}}}
\bibcite{SalomeBourdieu06}{{48}{}{{}}{{}}}
\bibcite{Sayer1990}{{49}{}{{}}{{}}}
\bibcite{ShumwayStoffer06}{{50}{}{{}}{{}}}
\bibcite{Song2005}{{51}{}{{}}{{}}}
\bibcite{Stevenson08}{{52}{}{{}}{{}}}
\bibcite{Stevenson2009}{{53}{}{{}}{{}}}
\bibcite{StosiekKonnerth03}{{54}{}{{}}{{}}}
\bibcite{Thompson88}{{55}{}{{}}{{}}}
\bibcite{Tibs96}{{56}{}{{}}{{}}}
\bibcite{TIP01}{{57}{}{{}}{{}}}
\bibcite{TRUC05}{{58}{}{{}}{{}}}
\bibcite{Tsien89}{{59}{}{{}}{{}}}
\bibcite{Vidne08}{{60}{}{{}}{{}}}
\bibcite{Vogelstein2009}{{61}{}{{}}{{}}}
\bibcite{WallaceHasan08}{{62}{}{{}}{{}}}
\bibcite{Yasuda2004}{{63}{}{{}}{{}}}
\bibcite{ImagingManual}{{64}{}{{}}{{}}}
\global \chardef \firstnote@num64\relax 
\global\NAT@numberstrue
\bibstyle{amsplain}
\newlabel{LastBibItem}{{64}{19}{}{}{}}
\newlabel{LastPage}{{}{19}}
