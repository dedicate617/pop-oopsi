\relax 
\citation{RamonyCajal04,RamonyCajal23}
\citation{MichevaSmith07}
\citation{Brainbow07}
\citation{Briggman2006}
\citation{HATS98,HARR03,Stein04,Santhanam06,Harris07}
\citation{Berry2004,Litke2004,Petrusca07,PILL07}
\citation{Tsien89}
\citation{Abeles91,Braitenberg1998}
\citation{ImagingManual}
\citation{StosiekKonnerth03}
\citation{WallaceHasan08}
\citation{Djurisic04}
\citation{ReddySaggau05,Iyer06,SalomeBourdieu06,ReddySaggau08}
\citation{NguyenParker01}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\newlabel{intro}{{1}{2}}
\citation{ImagingManual}
\citation{YaksiFriedrich06,GreenbergKerr08,Vogelstein2009}
\citation{BRIL88,CSK88,BRIL92,PG00,PILL07,PAN03d,PAN04c,Rigat06,TRUC05,NYK06,KP06,Vidne08,Stevenson2009}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}}
\newlabel{sec:methods}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Model}{3}}
\newlabel{sec:methods:markov-setup}{{2.1}{3}}
\citation{PAN04c,Escola07}
\citation{Escola07}
\citation{LD89,PAN04c}
\citation{Vogelstein2009}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A plot of the firing rate nonlinearity $f(J)$ used in our simulations; see Eq.\nobreakspace  {}1\hbox {}. Note that the firing rate saturates at $1/\Delta $, because of our Bernoulli assumption (i.e., the spike count per bin is at most one); $\Delta = (60$ Hz$)^{-1}$ here.}}{4}}
\newlabel{fig:egfluor}{{1}{4}}
\newlabel{eqn:glm:definition}{{1}{4}}
\newlabel{eqn:h:definition}{{3}{4}}
\citation{ImagingManual}
\citation{Vogelstein2009}
\citation{Yasuda2004}
\citation{Vogelstein2009}
\citation{Rigat06}
\newlabel{eqn:ca:definition}{{4}{5}}
\newlabel{eqn:F:definition}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Goal and general strategy}{5}}
\newlabel{sec:methods:goal}{{2.2}{5}}
\citation{DLR77,McLachlanKrishnan96}
\citation{RAB89}
\citation{Vogelstein2009}
\citation{ShumwayStoffer06}
\newlabel{eqn:loglik:definition-expl}{{6}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Initialization of ``intrinsic'' parameters via sequential Monte Carlo methods}{6}}
\newlabel{sec:methods:indep}{{2.3}{6}}
\citation{DGA00,DFG01,GDW04}
\citation{Vogelstein2009}
\newlabel{eqn:forward}{{7}{7}}
\newlabel{eqn:backward}{{8}{7}}
\newlabel{eq:particle-fb}{{9}{7}}
\newlabel{eqn:bw}{{10}{7}}
\citation{BickelBengtsson08}
\citation{RC05}
\citation{Andrieu2007}
\citation{NBR03}
\citation{NBR03}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Estimating joint posteriors over weakly coupled neurons}{8}}
\newlabel{sec:methods:joint}{{2.4}{8}}
\citation{NBR03}
\citation{NBR03}
\citation{Vogelstein2009}
\citation{Buhl94,Thompson88,Reyes98,Feldmeyer99,Gupta00,FeldmeyerSakmann00,PetersenSakmann00,Binzegger04,Song2005,Mishchenko2009b}
\citation{PAN04c,Rigat06,PILL07,Stevenson08}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}A factorized approximation of the joint posteriors}{9}}
\newlabel{sec:cheaper-high-snr}{{2.4.1}{9}}
\newlabel{eqn:indep_approx}{{13}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Estimating the functional connectivity matrix}{9}}
\newlabel{sec:methods:parameters HMM}{{2.5}{9}}
\citation{Tibs96,TIP01,DE03,NG04,Candes2005,Mishchenko2009}
\citation{CONV04}
\citation{Vogelstein2009}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Imposing a sparse prior on the functional connectivity}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Imposing Dale's law on the functional connectivity}{10}}
\citation{Braitenberg1998,Urquijo2000,Lefort2009,Sayer1990}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Pseudocode for estimating functional connectivity from calcium imaging data using EM; $\eta ^n$, $\eta ^F$, $N_G$ are user-defined convergence tolerance parameters.}}{11}}
\newlabel{eqn:pseudocode}{{1}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Specific implementation notes}{11}}
\newlabel{sec:methods:specific_implementation}{{2.6}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{11}}
\newlabel{sec:results}{{3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Simulating neural activity in a neural population}{11}}
\newlabel{sec:results:simulations}{{3.1}{11}}
\citation{Braitenberg1998,Urquijo2000}
\citation{Braitenberg1998,Lefort2009}
\citation{Lefort2009,Sayer1990}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Schematic overview. The raw observed data is a large-scale calcium fluorescence movie, which is pre-processed to correct for movement artifacts (in the in vivo setting) and find regions-of-interest (i.e., putative neurons); note that we have omitted details of these important preprocessing steps in this paper. Given the fluorescence traces from each neuron, we estimate the underlying spike trains (i.e., time series of neural activity) using statistical deconvolution methods. Then we estimate the parameters of a network model, given the observed data. Our major goal is to obtain an accurate estimate of the network connectivity matrix, which summarizes the information we are able to infer about the local neuronal microcircuit. This figure adapted from personal communications with Rafael Yuste, Brendon O.\ Watson, and Adam Packer.}}{12}}
\newlabel{fig:data_schematic}{{2}{12}}
\citation{}
\citation{Abeles01}
\citation{Koch99}
\citation{Sayer1990}
\citation{Koch99}
\citation{Vogelstein2009}
\citation{ImagingManual,HelmchenSakmann96,BrenowitzRegehr07}
\newlabel{eqn:convert}{{15}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Inferring functional connectivity from the simulated calcium imaging data}{13}}
\newlabel{sec:results:inference}{{3.2}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Scale bias in inferred connection weights due to coarse time discretization of calcium imaging data}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Table of simulation parameters. $\@mathcal {E}(\lambda )$ indicates an exponential distribution with $\lambda $, and $\@mathcal {N}(\mu ,\sigma ^2)$ indicates a truncated normal with mean $\mu $ and variance $\sigma ^2$, and lower bound of one standard deviation below the mean.}}{14}}
\newlabel{table:caparm}{{1}{14}}
\citation{VogPan09}
\citation{NguyenParker01,ReddySaggau05,Iyer06,SalomeBourdieu06,ReddySaggau08}
\citation{Vogelstein2009}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two in vivo fluorescence traces (top) and their corresponding inferred spike trains (bottom). The left panels show a high SNR case, that is sufficient quality for the factorized approximation to work nearly as well as the embedded-chain-within-Gibbs approach. The right panels show a low SNR case, in which the factorized approach is insufficient. The ordinate is in arbitrary units. Data from the laboratory of Tom Mrsic-Flogel.}}{15}}
\newlabel{fig:example_traces}{{3}{15}}
\newlabel{eqn:bias}{{17}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Functional connectivity matrix can be reconstructed from calcium imaging data. In the upper panels inferred connection weights are shown in a scatter plot versus real connection weights, with inference performed using factorized approximation algorithm, exact embedded-chain-within-blockwise-Gibbs approach, and original spike trains observed at the frame rate of the calcium imaging. Network of $N=25$ neurons was used, firing at $\approx 5$ Hz, and imaged for T=600 sec at intermediate SNR (photon budget 10Kph/neuron/frame, see below). $r^2=0.47$ for factorized approximation algorithm was found, $r^2=0.48$ for embedded-chain-within-blockwise-Gibbs approach, and $r^2=0.57$ for the original spike trains. Thus, factorized approximation produced results almost as accurate as the exact embedded-chain-within-blockwise-Gibbs approach, and almost as accurate as the original spikes. Inferred connectivity weights (upper left) were scaled with respect to true connectivity by a constant amount due to time discretization bias (see below); other than scale, inferred connectivity represented the true connectivity matrix very well (upper right). Thus, calcium imaging is sufficient to identify connected pairs of neurons reliably.}}{16}}
\newlabel{fig:scatters}{{4}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Impact of different imaging frame rates, noise levels, and durations on the estimator accuracy}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The low-frame rate of calcium imaging can explain the observed scale bias from Figure 4\hbox {}. Our theoretical scale bias is determined by considering what fraction of spikes would fall within a single image frame, which is a function of $\Delta $ (c.f. Eq. 17\hbox {}). The center of each square indicates the mean scale bias of 5 simulations, the extent of each square indicates one standard deviation, and the errorbars indicate the $95$th and $5$th percentiles. XXX Y: can you correct these details? XXX}}{17}}
\newlabel{fig:bias}{{5}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Accuracy of the estimates and Fisher information matrix}{17}}
\newlabel{sec:methods:accuracy_Fisher}{{3.5}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Accuracy of the inferred connectivity weights as function of the frame rate of calcium imaging. Connectivity matrix here was inferred from the original spike trains observed at corresponding frame rates, thus establishing the upper performance bound for inference using calcium imaging data. A network of $N=25$ neurons, firing at $\approx 5$ Hz and imaged for $T=600$ sec was used.}}{18}}
\newlabel{fig:recvar}{{6}{18}}
\newlabel{eqn:fisher}{{19}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Accuracy of inferred connectivity weights as function of the noise amount in the calcium imaging data, as quantified by experimental photon budget per neuron-frame, for frame rates of 15 Hz, 33 Hz and 66 Hz. Photon counts on the order of 20-40 Kph/frame/neuron are required to achieve the upper bound due by the frame rate. Connectivity matrix here was inferred from simulated fluorescence data using factorized approximation algorithm. Simulation conditions are the same as in Figure 6\hbox {}. Vertical black lines indicate noise levels for the two example traces shown in Figure 3\hbox {}, as determined using the SMC approach to estimate $\theta _i$ as described in Section 2.3\hbox {}.}}{19}}
\newlabel{fig:recvar-SNR}{{7}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Impact of using priors on the inference}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Impact of strong correlations and deviations from generative model on the inference}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Accuracy of inferred connectivity weights as function of the imaging time and neural population size. Incorporating simple priors such as exponential prior on the connectivity weights allows to boost reconstruction accuracy dramatically (dashed lines). In this latter case, $T=300$ sec is already sufficient to recover 70\% of the variance in the connection weights. Incorporating Dale's prior leads to only marginal improvement (dotted line). As shown in the methods, reconstruction accuracy does not depend on the neural population size $N$. Here, neural population from $N=10$ to $N=200$ were simulated for different $T$, where $N=200$ (gray) and $N=100$ (black) are shown. All networks were prepared in similar state by adjusting strength of inhibitory connections to achieve similar mean firing rate $\approx 5$ Hz, although actual firing rate in these networks could vary. In all cases, $T=5$ min - 0.5 hour is sufficient to produce accurate reconstructions. }}{20}}
\newlabel{fig:recvar-NT}{{8}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Incorporating simple priors on the distribution of connectivity weights in the Bayesian inference algorithm, such as exponential sparseness prior, is essential to achieve much more accurate reconstructions than using simple GLM from a smaller amount of calcium imaging data. Here, connection weights reconstructed using simple GLM (left panel) or sparse-prior GLM (right panel) are shown in a scatter plot for a network of $N=50$ neurons firing at $\approx 5$ Hz and imaged for $T=600$ sec. $r^2=0.64$ for simple GLM solution and $r^2=0.85$ for sparse-GLM solution.}}{21}}
\newlabel{fig:sparse}{{9}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Distribution of inferred connection weights using simple GLM (left) and sparse GLM (right) vs true distributions. When sparse exponential prior on the distribution of connection weights is enacted, dispersion in inferred connection weights is substantially reduced and, in particular, it becomes possible to reliably determine which neural pairs are connected. Distributions are shown for a network of $N=200$ neurons firing at $\approx 5$ Hz and imaged for $T=600$ s was used here.}}{22}}
\newlabel{fig:distros}{{10}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  Diverseness of observed neural activity patterns is required for functional connectivity to give access to the actual ``anatomical'' structure of the neural circuit. Here, 15 sec of simulated spike trains for a weakly coupled network (upper-left) and a network with strongly coupled component (upper-right) are shown. In weakly coupled network spikes are sufficiently uncorrelated to give access to all different neural activity patterns needed to properly estimate true weights ${\bf  w}_i$. In strongly coupled case, many instances of highly synchronous locked firings are evident, thus preventing observation of sufficiently rich ensemble of activity patterns. Accordingly, GLM solution for the strongly coupled neural network (lower-right) does not represent the true connectivity of the circuit, even for the weakly coupled circuit's component. This is contrary to the weakly-coupled network (lower-left) where true connectivity is successfully estimated. Networks of $N=50$ neurons firing at $\approx 5$ Hz and imaged for $T=600$ sec were used to produce this figure.}}{23}}
\newlabel{fig:rasters}{{11}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Bayesian inference algorithm is robust to distortions of the underlying generative model. One distortion that should be expected is variability of the EPSP time courses from neuron to neuron, and possibly synapse to synapse. With up to 25\% variability allowed in EPSP time scales $\tau _w$ (right panel) our algorithm provided reconstructions of the same quality as when all $\tau _w$ were the same (left panel). Simulation conditions are the same as in Figure 6\hbox {}.}}{24}}
\newlabel{fig:vartau}{{12}{24}}
\citation{Chlovksii}
\citation{emory, liam, Garofalo, Vakorina, etc.}
\citation{Duane 1 and 2, liam}
\bibdata{mybib}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{25}}
\newlabel{sec:discussion}{{4}{25}}
\bibcite{Abeles91}{Abeles, 1991}
\bibcite{Andrieu2007}{Andrieu et\nobreakspace  {}al., 2007}
\bibcite{BickelBengtsson08}{Bickel et\nobreakspace  {}al., 2008}
\bibcite{Binzegger04}{Binzegger et\nobreakspace  {}al., 2004}
\bibcite{CONV04}{Boyd and Vandenberghe, 2004}
\bibcite{Braitenberg1998}{Braitenberg and Schuz, 1998}
\bibcite{BrenowitzRegehr07}{Brenowitz and Regehr, 2007}
\bibcite{Briggman2006}{Briggman and Denk, 2006}
\bibcite{BRIL88}{Brillinger, 1988}
\bibcite{BRIL92}{Brillinger, 1992}
\bibcite{Buhl94}{Buhl et\nobreakspace  {}al., 1994}
\bibcite{Candes2005}{Candes and Romberg, 2005}
\bibcite{CSK88}{Chornoboy et\nobreakspace  {}al., 1988}
\bibcite{DLR77}{Dempster et\nobreakspace  {}al., 1977}
\bibcite{Djurisic04}{Djurisic et\nobreakspace  {}al., 2004}
\bibcite{DE03}{Donoho and Elad, 2003}
\bibcite{DFG01}{Doucet et\nobreakspace  {}al., 2001}
\bibcite{DGA00}{Doucet et\nobreakspace  {}al., 2000}
\bibcite{Escola07}{Escola and Paninski, 2008}
\bibcite{Feldmeyer99}{Feldmeyer et\nobreakspace  {}al., 1999}
\bibcite{FeldmeyerSakmann00}{Feldmeyer and Sakmann, 2000}
\bibcite{GDW04}{Godsill et\nobreakspace  {}al., 2004}
\bibcite{Urquijo2000}{Gomez-Urquijo et\nobreakspace  {}al., 2000}
\bibcite{GreenbergKerr08}{Greenberg et\nobreakspace  {}al., 2008}
\bibcite{Gupta00}{Gupta et\nobreakspace  {}al., 2000}
\bibcite{HARR03}{Harris et\nobreakspace  {}al., 2003}
\bibcite{HATS98}{Hatsopoulos et\nobreakspace  {}al., 1998}
\bibcite{HelmchenSakmann96}{Helmchen et\nobreakspace  {}al., 1996}
\bibcite{Iyer06}{Iyer et\nobreakspace  {}al., 2006}
\bibcite{Koch99}{Koch, 1999}
\bibcite{KP06}{Kulkarni and Paninski, 2007}
\bibcite{Lefort2009}{Lefort et\nobreakspace  {}al., 2009}
\bibcite{LD89}{Li and Duan, 1989}
\bibcite{Litke2004}{Litke et\nobreakspace  {}al., 2004}
\bibcite{Brainbow07}{Livet et\nobreakspace  {}al., 2007}
\bibcite{Harris07}{Luczak et\nobreakspace  {}al., 2007}
\bibcite{McLachlanKrishnan96}{McLachlan and Krishnan, 1996}
\bibcite{MichevaSmith07}{Micheva and Smith, 2007}
\bibcite{Mishchenko2009}{Mishchenko, 2009}
\bibcite{Mishchenko2009b}{Mishchenko et\nobreakspace  {}al., 2009}
\bibcite{NBR03}{Neal et\nobreakspace  {}al., 2003}
\bibcite{NG04}{Ng, 2004}
\bibcite{NguyenParker01}{Nguyen et\nobreakspace  {}al., 2001}
\bibcite{NYK06}{Nykamp, 2007}
\bibcite{PAN04c}{Paninski, 2004}
\bibcite{PAN03d}{Paninski et\nobreakspace  {}al., 2004}
\bibcite{PetersenSakmann00}{Petersen and Sakmann, 2000}
\bibcite{Petrusca07}{Petrusca et\nobreakspace  {}al., 2007}
\bibcite{PILL07}{Pillow et\nobreakspace  {}al., 2008}
\bibcite{PG00}{Plesser and Gerstner, 2000}
\bibcite{RAB89}{Rabiner, 1989}
\bibcite{RamonyCajal04}{Ramon\nobreakspace  {}y Cajal, 1904}
\bibcite{RamonyCajal23}{Ramon\nobreakspace  {}y Cajal, 1923}
\bibcite{ReddySaggau08}{Reddy et\nobreakspace  {}al., 2008}
\bibcite{ReddySaggau05}{Reddy and Saggau, 2005}
\bibcite{Reyes98}{Reyes et\nobreakspace  {}al., 1998}
\bibcite{Rigat06}{Rigat et\nobreakspace  {}al., 2006}
\bibcite{RC05}{Robert and Casella, 2005}
\bibcite{SalomeBourdieu06}{Salome et\nobreakspace  {}al., 2006}
\bibcite{Santhanam06}{Santhanam et\nobreakspace  {}al., 2006}
\bibcite{Sayer1990}{Sayer et\nobreakspace  {}al., 1990}
\bibcite{Berry2004}{Segev et\nobreakspace  {}al., 2004}
\bibcite{ShumwayStoffer06}{Shumway and Stoffer, 2006}
\bibcite{Song2005}{Song et\nobreakspace  {}al., 2005}
\bibcite{Stein04}{Stein et\nobreakspace  {}al., 2004}
\bibcite{Stevenson08}{Stevenson et\nobreakspace  {}al., 2008}
\bibcite{Stevenson2009}{Stevenson et\nobreakspace  {}al., 2009}
\bibcite{StosiekKonnerth03}{Stosiek et\nobreakspace  {}al., 2003}
\bibcite{Thompson88}{Thompson et\nobreakspace  {}al., 1988}
\bibcite{Tibs96}{Tibshirani, 1996}
\bibcite{TIP01}{Tipping, 2001}
\bibcite{TRUC05}{Truccolo et\nobreakspace  {}al., 2005}
\bibcite{Tsien89}{Tsien, 1989}
\bibcite{Vidne08}{Vidne et\nobreakspace  {}al., 2009}
\bibcite{Vogelstein2009}{Vogelstein et\nobreakspace  {}al., 2009}
\bibcite{WallaceHasan08}{Wallace et\nobreakspace  {}al., 2008}
\bibcite{YaksiFriedrich06}{Yaksi and Friedrich, 2006}
\bibcite{Yasuda2004}{Yasuda et\nobreakspace  {}al., 2004}
\bibcite{ImagingManual}{Yuste et\nobreakspace  {}al., 2006}
\bibstyle{apalike}
